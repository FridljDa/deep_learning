{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/default/miniconda3/envs/deep_learning_2023/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# This data handling code is adapted from the PyTorch geometric collection of google colab notebooks, a fantastic resource for getting started with GNNs. https://pytorch-geometric.readthedocs.io/en/latest/notes/colabs.html\n",
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch_geometric.data import DataLoader\n",
    "# import the graph classifier you built in the last step\n",
    "from GCN_03 import NodeClassifier, NodeClassifierWelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: Cora():\n",
      "====================\n",
      "Number of graphs: 1\n",
      "Number of features: 1433\n",
      "Number of classes: 7\n",
      "\n",
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
      "=============================================================\n",
      "Number of nodes: 2708\n",
      "Number of edges: 10556\n",
      "Average node degree: 3.90\n",
      "Contains isolated nodes: False\n",
      "Contains self-loops: False\n",
      "Is undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/default/miniconda3/envs/deep_learning_2023/lib/python3.9/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'contains_isolated_nodes' is deprecated, use 'has_isolated_nodes' instead\n",
      "  warnings.warn(out)\n",
      "/Users/default/miniconda3/envs/deep_learning_2023/lib/python3.9/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'contains_self_loops' is deprecated, use 'has_self_loops' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# - - - DATA PREPARATIONS - - -\n",
    "\n",
    "dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Contains isolated nodes: {data.contains_isolated_nodes()}')\n",
    "print(f'Contains self-loops: {data.contains_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of tensor a (2708) must match the size of tensor b (13264) at non-singleton dimension 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    out = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "    loss = criterion(out[data.train_mask],\n",
    "                     data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "    test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n",
    "    test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n",
    "    return test_acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = NodeClassifier(num_node_features=1433, hidden_features=16, num_classes=7)\n",
    "optimizer = torch.optim.Adam(model_new.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Loss: 1.8473, Test Accuracy: 0.26\n",
      "Epoch: 020, Loss: 1.5505, Test Accuracy: 0.427\n",
      "Epoch: 030, Loss: 1.1373, Test Accuracy: 0.42\n",
      "Epoch: 040, Loss: 0.9260, Test Accuracy: 0.516\n",
      "Epoch: 050, Loss: 0.6530, Test Accuracy: 0.572\n",
      "Epoch: 060, Loss: 0.4179, Test Accuracy: 0.664\n",
      "Epoch: 070, Loss: 0.5334, Test Accuracy: 0.625\n",
      "Epoch: 080, Loss: 0.3605, Test Accuracy: 0.681\n",
      "Epoch: 090, Loss: 0.2012, Test Accuracy: 0.67\n",
      "Epoch: 100, Loss: 0.1835, Test Accuracy: 0.672\n",
      "Epoch: 110, Loss: 0.1950, Test Accuracy: 0.643\n",
      "Epoch: 120, Loss: 0.1559, Test Accuracy: 0.689\n",
      "Epoch: 130, Loss: 0.1862, Test Accuracy: 0.697\n",
      "Epoch: 140, Loss: 0.0799, Test Accuracy: 0.665\n",
      "Epoch: 150, Loss: 0.1277, Test Accuracy: 0.683\n",
      "Epoch: 160, Loss: 0.0601, Test Accuracy: 0.677\n",
      "Epoch: 170, Loss: 0.0823, Test Accuracy: 0.679\n",
      "Epoch: 180, Loss: 0.0749, Test Accuracy: 0.658\n",
      "Epoch: 190, Loss: 0.0915, Test Accuracy: 0.673\n",
      "Epoch: 200, Loss: 0.0520, Test Accuracy: 0.647\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 201):\n",
    "    loss = train(model_new)\n",
    "    if epoch % 10 == 0:\n",
    "        test_acc = test(model_new)\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Test Accuracy: {test_acc}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old model (Welling et al., 2011) for node classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_welling = NodeClassifierWelling(num_node_features=1433, hidden_features=16, num_classes=7)\n",
    "optimizer = torch.optim.Adam(model_welling.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Loss: 1.8950, Test Accuracy: 0.378\n",
      "Epoch: 020, Loss: 1.7912, Test Accuracy: 0.333\n",
      "Epoch: 030, Loss: 1.6343, Test Accuracy: 0.447\n",
      "Epoch: 040, Loss: 1.4142, Test Accuracy: 0.553\n",
      "Epoch: 050, Loss: 1.2101, Test Accuracy: 0.654\n",
      "Epoch: 060, Loss: 0.9750, Test Accuracy: 0.727\n",
      "Epoch: 070, Loss: 0.7839, Test Accuracy: 0.742\n",
      "Epoch: 080, Loss: 0.6451, Test Accuracy: 0.754\n",
      "Epoch: 090, Loss: 0.5383, Test Accuracy: 0.761\n",
      "Epoch: 100, Loss: 0.3967, Test Accuracy: 0.756\n",
      "Epoch: 110, Loss: 0.3238, Test Accuracy: 0.778\n",
      "Epoch: 120, Loss: 0.2910, Test Accuracy: 0.773\n",
      "Epoch: 130, Loss: 0.2634, Test Accuracy: 0.771\n",
      "Epoch: 140, Loss: 0.2391, Test Accuracy: 0.787\n",
      "Epoch: 150, Loss: 0.2010, Test Accuracy: 0.777\n",
      "Epoch: 160, Loss: 0.1548, Test Accuracy: 0.784\n",
      "Epoch: 170, Loss: 0.1632, Test Accuracy: 0.77\n",
      "Epoch: 180, Loss: 0.1594, Test Accuracy: 0.78\n",
      "Epoch: 190, Loss: 0.1382, Test Accuracy: 0.778\n",
      "Epoch: 200, Loss: 0.1668, Test Accuracy: 0.779\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 201):\n",
    "    loss = train(model_welling)\n",
    "    if epoch % 10 == 0:\n",
    "        test_acc = test(model_welling)\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Test Accuracy: {test_acc}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new model model has lower loss, but also lower accuracy. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
