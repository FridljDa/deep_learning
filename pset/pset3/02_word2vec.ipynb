{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 Word2Vec & Seq2Seq Models\n",
    "---------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/default/miniconda3/envs/deep_learning_2023/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Global seed set to 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys,  json, pickle, tqdm, random, warnings \n",
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "import matplotlib as mpl, matplotlib.pyplot as plt#, seaborn as sns\n",
    "\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils import data\n",
    "\n",
    "from gensim.models import Word2Vec, Phrases\n",
    "from gensim.test.utils import common_texts\n",
    "import gensim, gensim.downloader as gensim_api\n",
    "from gensim import corpora\n",
    "\n",
    "from gensim.parsing.preprocessing import remove_stopwords, preprocess_documents\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "pl.seed_everything(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: you can find other `gensim` datasets [here](https://github.com/RaRe-Technologies/gensim-data#datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/default/Google Drive/currentDocumants/studies/Master/6.Semester/deep_learning/pset/pset3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAVE_DIR = os.path.abspath('.')\n",
    "\n",
    "W2V_FILE = os.path.join(SAVE_DIR, 'word2vec.pth')\n",
    "\n",
    "CORPUS = 'text8'\n",
    "\n",
    "TXT_FILE = os.path.join(SAVE_DIR, f'{CORPUS}.pkl')\n",
    "\n",
    "OVERWRITE = False\n",
    "\n",
    "VEC_SIZE = 50\n",
    "\n",
    "DEVICE = 'cpu'\n",
    "\n",
    "SAVE_DIR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch you text corpus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: generate your own word-vector embedding using a text corpus of _your_ choice of at least **500** words. You may use `gensim`'s corpora.\n",
    "\n",
    "Feel free to play with hyperparmaters in the notebook such as context size and embedding size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = gensim_api.load('text8')  # download the corpus and return it opened as an iterable\n",
    "#length of Dataset corpus\n",
    "corpus_vec = [word for _, word in enumerate(corpus)]\n",
    "#corpus.shape\n",
    "#len(corpus)\n",
    "#get type of corpus\n",
    "#type(corpus)\n",
    "#corpus\n",
    "#for i, word in enumerate(corpus):\n",
    "#    if i < 10:\n",
    "#        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#does_corpus_exist = os.path.isfile(\"data/Faust.txt\")\n",
    "\n",
    "#if not does_corpus_exist or OVERWRITE:\n",
    "#    corpus = gensim_api.load(CORPUS)\n",
    "#    with open(TXT_FILE, 'wb') as f:\n",
    "#        pickle.dump(corpus, f)\n",
    "\n",
    "#else:\n",
    "#    with open(TXT_FILE, 'rb') as f:\n",
    "#        corpus = pickle.load(f)\n",
    "\n",
    "#corpus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train your Word2Vec Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: you are free to create your own Word2Vec model. You are welcome to use `gensim`. However for the pset you must at least _train_ a Word2Vec model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "does_model_exist = os.path.isfile(W2V_FILE)\n",
    "\n",
    "if not does_model_exist or OVERWRITE:\n",
    "    w2v = Word2Vec(\n",
    "        # NOTE: you can use either a list of strings (sentences)\n",
    "        # or provide a corpus_file\n",
    "        corpus, \n",
    "        \n",
    "        # Dimensionality of the word vectors.\n",
    "        vector_size=VEC_SIZE, \n",
    "        \n",
    "        # Maximum distance between the current and predicted word within a sentence.\n",
    "        window=5, \n",
    "\n",
    "        # Ignores all words with total frequency lower than this.\n",
    "        min_count=1,\n",
    "\n",
    "        # Training algorithm: 1 for skip-gram; otherwise CBOW.\n",
    "        sg = 1,\n",
    "        \n",
    "        # Use these many worker threads to train the model (=faster training \n",
    "        # with multicore machines).\n",
    "        workers=32,\n",
    "\n",
    "        # If 0, use the sum of the context word vectors. If 1, use the mean, \n",
    "        # only applies when cbow is used.\n",
    "        cbow_mean = 1,\n",
    "\n",
    "        # Number of iterations (epochs) over the corpus. (Formerly: iter)\n",
    "        epochs=100\n",
    "    )\n",
    "\n",
    "    w2v.add_null_word()\n",
    "\n",
    "    w2v.save(W2V_FILE)\n",
    "\n",
    "else:\n",
    "\n",
    "     w2v = Word2Vec.load(W2V_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3959814802.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[11], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    match arg:\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Simple utility function for doing vector math based on a string\n",
    "def vec_math(model, *args, return_str_description:bool=False):    \n",
    "    desc = ''\n",
    "    func = np.add  \n",
    "    # NOTE: vector_size  \n",
    "    vect = None\n",
    "    \n",
    "    for arg in args:\n",
    "        match arg:\n",
    "            case '+':\n",
    "                desc+= ' + '\n",
    "                func = np.add\n",
    "\n",
    "            case '-':\n",
    "                desc+= ' - '\n",
    "                func = np.subtract\n",
    "                \n",
    "            case '/':\n",
    "                desc+= ' / '\n",
    "                func = np.divide\n",
    "\n",
    "            case '*':\n",
    "                desc+= ' * '\n",
    "                func = np.multiply\n",
    "\n",
    "            case _:\n",
    "                desc += arg\n",
    "                curr = model.wv[arg]\n",
    "                if vect is None:\n",
    "xvect = curr.copy()\n",
    "                else:\n",
    "                    vect = func(vect, curr)\n",
    "\n",
    "    if return_str_description:\n",
    "        desc, vect\n",
    "\n",
    "    return vect\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: here my model had \n",
    "\n",
    "$$\n",
    "woman + man - king = girl\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "news + truth - lies = blogging\n",
    "$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# woman + man - king = ?\n",
    "gsm_res = w2v.wv.most_similar(positive=['woman','man'], negative=['king'])[0]\n",
    "gsm_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news + truth - lies = ?\n",
    "gsm_res = w2v.wv.most_similar(positive=['news','truth'], negative=['lies'])[0]\n",
    "gsm_res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Plot these word embeddings (all words) by adjusting the code in the notebook.\n",
    "\n",
    "You are able to adjust the plotting parameters to suit your needs for making a compelling visualization. \n",
    "Discuss what you notice in your embeddings. For example, using the introduction to Charles Darwin's \"_On the Origin of Species_\" \n",
    "as a text file, we obtain the embeddings in Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: modified code from below here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Since this is too crowded to interpret, modify the code in the notebook to randomly select words to plot as long as there is space as shown in Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 8))\n",
    "lim_scale = 2\n",
    "\n",
    "word_groups = [\n",
    "    'computer,news,truth,lies,blogging,news + truth - lies'.split(','), \n",
    "    'man,king,woman,queen,woman + man - king'.split(','), \n",
    "]\n",
    "\n",
    "for i, words in enumerate(word_groups):\n",
    "    ax = fig.add_subplot(1, 2, i+1)\n",
    "    single_words = list(filter(lambda e: e.isalpha(), words))\n",
    "    domath_words = list(filter(lambda e: not e.isalpha(), words))\n",
    "\n",
    "    vecs = w2v.wv[single_words]\n",
    "    for w in domath_words:        \n",
    "        v = vec_math(w2v, *w.split())\n",
    "        vecs = np.vstack((vecs, v))      \n",
    "\n",
    "    min_vals = np.min(vecs, axis=0)\n",
    "    max_vals = np.max(vecs, axis=0)  \n",
    "\n",
    "    ax.set_xlim(min_vals[0] * lim_scale, max_vals[0] * lim_scale)\n",
    "    ax.set_ylim(min_vals[1] * lim_scale, max_vals[1] * lim_scale)\n",
    "\n",
    "    for j, vec in enumerate(vecs):\n",
    "        word = words[j]\n",
    "\n",
    "        plt.scatter(vec[0], vec[1])\n",
    "        plt.annotate(\n",
    "            word, xy=(0, 0),  xytext=(vec[0], vec[1]), \n",
    "            arrowprops=dict(arrowstyle=\"<-\")\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whether or not you used `gensim` for training the `Word2Vec` model you will be using PyTorch Lightning for the `Seq2Seq` model. To make this easier on you, you will need to create a `data.Dataset` object which contains, at the very least, `__getitem__` and `__len__` methods to yield items during training. Below is an example which converts a `gensim` corpus paired batches of the first 300 words per doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqTextDataset(data.Dataset):\n",
    "    def __init__(self, corpus, keyed_vecs, reverse_target:bool=False):        \n",
    "        self.corpus = corpus\n",
    "        self.keyed_vecs = keyed_vecs\n",
    "        \n",
    "        docs = self.docs_from_corpus(corpus)\n",
    "        self.docs = docs\n",
    "        self.data = docs\n",
    "\n",
    "        corpora_dct = corpora.Dictionary(docs)\n",
    "        self.corpora_dct = corpora_dct\n",
    "\n",
    "        bows = self.bows_from_docs(docs, corpora_dct)\n",
    "        self.bows = bows\n",
    "        \n",
    "        self.reverse_target = reverse_target\n",
    "\n",
    "    def docs_from_corpus(self, corpus):\n",
    "        docs = [\n",
    "            simple_preprocess(remove_stopwords(' '.join(doc)))[:300] \n",
    "            for doc in corpus\n",
    "        ]\n",
    "        return docs\n",
    "        \n",
    "    def bows_from_docs(self, docs, dct):\n",
    "        return [dct.doc2bow(doc) for doc in docs]\n",
    "\n",
    "\n",
    "    def __len__(self):        \n",
    "        return int(len(self.docs))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        doc = self.docs[idx]\n",
    "\n",
    "        source = torch.tensor([self.keyed_vecs.get_index(word) for word in doc])      \n",
    "        \n",
    "        target = [self.keyed_vecs.get_index(word) for word in doc]\n",
    "        if self.reverse_target:\n",
    "            target = target[::-1]\n",
    "        target = torch.tensor(target)\n",
    "\n",
    "        return source, target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: fill in the `encode` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        n_vocabsize:int, n_embedding:int, n_hidden:int, n_layers:int, \n",
    "        dropout:Optional[float]=0.1, pretrained:Optional[np.ndarray]=None,\n",
    "    ):\n",
    "        super(Encoder, self).__init__()\n",
    "                \n",
    "        self.n_vocabsize = n_vocabsize\n",
    "        self.n_embedding = n_embedding\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        embedding = self.make_embedding_layer(n_vocabsize, n_embedding, pretrained)\n",
    "        self.embedding = embedding\n",
    "\n",
    "        # NOTE: depending on your dataset you may have to change batch_first\n",
    "        self.lstm = nn.LSTM(n_embedding, n_hidden, n_layers, dropout=dropout, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def make_embedding_layer(\n",
    "        self, \n",
    "        n_vocabsize:int, \n",
    "        n_embedding:int,\n",
    "        pretrained:Optional[np.ndarray]=None,\n",
    "    ):\n",
    "        if pretrained is not None:\n",
    "            pretrained = np.array(pretrained)\n",
    "            n_vocabsize, n_embedding = pretrained.shape\n",
    "            \n",
    "            self.n_vocabsize = n_vocabsize\n",
    "            self.n_embedding = n_embedding\n",
    "\n",
    "            pretrained = torch.FloatTensor(pretrained) \n",
    "            embedding = nn.Embedding.from_pretrained(pretrained)\n",
    "\n",
    "        else:\n",
    "            embedding = nn.Embedding(n_vocabsize, n_embedding)\n",
    "\n",
    "        return embedding\n",
    "    \n",
    "\n",
    "    def encode(self, x):\n",
    "       # TODO: fill this in\n",
    "       pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.encode(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: fill in the `decode` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_vocabsize:int, n_embedding:int, n_hidden:int, n_layers:int, \n",
    "        dropout:Optional[float]=0.1,\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_vocabsize = n_vocabsize\n",
    "        self.n_embedding = n_embedding\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(n_vocabsize, n_embedding)\n",
    "        self.lstm = nn.LSTM(n_embedding, n_hidden, n_layers, dropout=dropout, batch_first=False)\n",
    "        self.fc_out = nn.Linear(n_hidden, n_vocabsize)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def decode(self, x, hidden, cell):\n",
    "        # TODO: fill this in\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def forward(self, x, hidden, cell):\n",
    "        return self.decode(x, hidden, cell)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seq2Seq LightningModule"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: fill in the `do_seq2seq` method and define the `criterion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(pl.LightningModule):    \n",
    "    def __init__(\n",
    "        self, \n",
    "        word_2_vec,\n",
    "        train_loader,\n",
    "        n_vocabsize:int=0, \n",
    "        n_hidden:int = 2,\n",
    "        n_layers:int = 2,\n",
    "        dropout:float = 0.2,\n",
    "        teacher_forcing_ratio:float=0.5,\n",
    "        learning_rate:float=0.01,\n",
    "    ):\n",
    "                \n",
    "        super(Seq2Seq, self).__init__()\n",
    "\n",
    "        self.w2v = word_2_vec\n",
    "        self.train_loader = train_loader\n",
    "\n",
    "        n_embedding = word_2_vec.vector_size\n",
    "        n_vocabsize, n_embedding = np.array(word_2_vec.wv).shape\n",
    "\n",
    "        self.n_vocabsize = n_vocabsize\n",
    "        self.n_embedding = n_embedding\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_layers = n_layers\n",
    "        self.n_output = n_vocabsize\n",
    "\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.encoder = Encoder(\n",
    "            n_vocabsize, n_embedding, n_hidden, n_layers, \n",
    "            dropout, pretrained=np.array(word_2_vec.wv)\n",
    "        )\n",
    "        self.decoder = Decoder(\n",
    "            n_vocabsize, n_embedding, n_hidden, n_layers, dropout,\n",
    "        )\n",
    "\n",
    "        # TODO: self.criterion = loss_fn\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.train_loader\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate, weight_decay=1e-5)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, 100, gamma=0.99)\n",
    "        return [optimizer], [scheduler]\n",
    "    \n",
    "    def encode(self, word):\n",
    "        index = self.w2v.wv.get_index(word)\n",
    "        return torch.tensor(index)\n",
    "    \n",
    "    def do_seq2seq(self, source, target):\n",
    "        # TODO: fill this in\n",
    "        pass\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        source = x\n",
    "        target = y\n",
    "\n",
    "        output = self.do_seq2seq(source, target)\n",
    "\n",
    "        # NOTE: this may not be needed depending on your\n",
    "        output_dim = output.shape[-1]        \n",
    "        output = output.view(-1, output_dim)\n",
    "        target = target.view(-1)\n",
    "\n",
    "\n",
    "        loss = self.criterion(output, target)\n",
    "\n",
    "        result = {'loss': loss}\n",
    "        self.log('loss', loss)\n",
    "        return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate dataset and dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Seq2SeqTextDataset(corpus, w2v.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = data.DataLoader(ds, batch_size=3, shuffle=True, drop_last=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(253854, 50)\n",
       "    (lstm): LSTM(50, 12, num_layers=4, batch_first=True, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(253854, 50)\n",
       "    (lstm): LSTM(50, 12, num_layers=4, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=12, out_features=253854, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s = Seq2Seq(\n",
    "    w2v, dl,\n",
    "    n_hidden=12, n_layers=4, dropout=0.5\n",
    ").to(DEVICE)\n",
    "s2s.encoder.to(DEVICE)\n",
    "s2s.decoder.to(DEVICE)\n",
    "s2s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/solstice/anaconda3/envs/lstm/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=1,\n",
    "    \n",
    "    # NOTE: gradient clipping can help prevent exploding gradients\n",
    "    gradient_clip_val=100,\n",
    "    gradient_clip_algorithm='value',    \n",
    "    log_every_n_steps=5,\n",
    "    \n",
    "    # NOTE: this should match your device i.e. if you set cuda above, this should be cuda. \n",
    "    # Otherwise it should be cpu. \n",
    "    accelerator=DEVICE,    \n",
    "    \n",
    "    # NOTE: you can set the maximum time you want to train your model\n",
    "    max_time={'minutes': 2},    \n",
    "\n",
    "    # NOTE: setting this to true will save your model every so often\n",
    "    enable_checkpointing=False,\n",
    "    accumulate_grad_batches=2\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | encoder   | Encoder          | 12.7 M\n",
      "1 | decoder   | Decoder          | 16.0 M\n",
      "2 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "16.0 M    Trainable params\n",
      "12.7 M    Non-trainable params\n",
      "28.7 M    Total params\n",
      "114.797   Total estimated model params size (MB)\n",
      "/home/solstice/anaconda3/envs/lstm/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "918da39c6069419182fa0d5696a1e2c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Time limit reached. Elapsed time is 0:02:25. Signaling Trainer to stop.\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(s2s, dl)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Train your network also to reconstruct sentences with some words masked. How well does this training perform? Report accuracy at convergence."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source, target in dl:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 253854])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = s2s.do_seq2seq(\n",
    "    source[0, :].unsqueeze(0),\n",
    "    target[0, :].unsqueeze(0)\n",
    ")\n",
    "res = res.squeeze(1)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[w2v.wv.index_to_key[idx] for idx in res.argmax(1)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Put in a sentence from the corpus and write its reconstruction. Is the reconstruction perfect?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Now mask one of the words in the sentence with xxxx and test if it fills the word back."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Finally, start a sentence from the corpus by giving the first 3 words, with the rest of the words masked, see if it completes this sentence."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use `gensim` to load other models aside from `Word2Vec` such as `glove` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors = gensim_api.load('glove-twitter-25')\n",
    "glove_vectors.most_similar('twitter')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook adapts parts of [@Ben Trevett](https://github.com/bentrevett)'s PyTorch Seq2Seq [notebook](https://github.com/bentrevett/pytorch-seq2seq/blob/master/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb). Additionally we utilize parts of both PyTorch's [documentation](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html) as well as [Gensim](https://radimrehurek.com/gensim/intro.html)'s and [Machine Learning Plus](https://www.machinelearningplus.com/)'s [tutorial](https://www.machinelearningplus.com/nlp/gensim-tutorial/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplementary materials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those getting started with [`gensim`](https://radimrehurek.com/gensim/intro.html) they may find [Gaurav Padawe](https://medium.com/@grvpdw92) [tutorial](https://medium.com/analytics-vidhya/word2vector-using-gensim-e055d35f1cb4) useful. Of course there is also the official `Word2Vec` `gensim` [tutorial](https://radimrehurek.com/gensim/models/word2vec.html)\n",
    "\n",
    "For support with [Pylightning](https://lightning.ai/docs/pytorch/stable/) please refer to these documentation pages:\n",
    "- `Trainer` [documentation](https://lightning.ai/docs/pytorch/stable/common/trainer.html)\n",
    "- `LightningModule` [documentation](https://lightning.ai/docs/pytorch/stable/common/lightning_module.html)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "48405d14813ffd37f8be7251e92423799cab262faebc8080a71f67eaa8a9635a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
