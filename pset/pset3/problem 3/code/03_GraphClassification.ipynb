{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/default/miniconda3/envs/deep_learning_2023/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# This data handling code is adapted from the PyTorch geometric collection of google colab notebooks, a fantastic resource for getting started with GNNs. https://pytorch-geometric.readthedocs.io/en/latest/notes/colabs.html\n",
    "import torch\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.transforms import Constant\n",
    "# import the graph classifier you built in the last step\n",
    "from GCN_03 import GraphClassifier, GraphClassifierWelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/REDDIT-BINARY.zip\n",
      "Extracting data/TUDataset/REDDIT-BINARY/REDDIT-BINARY.zip\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: REDDIT-BINARY(2000):\n",
      "====================\n",
      "Number of graphs: 2000\n",
      "Number of features: 1\n",
      "Number of classes: 2\n",
      "\n",
      "Data(edge_index=[2, 480], y=[1], x=[218, 1], num_nodes=218)\n",
      "=============================================================\n",
      "Number of nodes: 218\n",
      "Number of edges: 480\n",
      "Average node degree: 2.20\n",
      "Contains isolated nodes: False\n",
      "Contains self-loops: False\n",
      "Is undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "/Users/default/miniconda3/envs/deep_learning_2023/lib/python3.9/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'contains_isolated_nodes' is deprecated, use 'has_isolated_nodes' instead\n",
      "  warnings.warn(out)\n",
      "/Users/default/miniconda3/envs/deep_learning_2023/lib/python3.9/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'contains_self_loops' is deprecated, use 'has_self_loops' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# - - - DATA PREPARATIONS - - -\n",
    "dataset = TUDataset(\n",
    "    root='data/TUDataset',\n",
    "    name='REDDIT-BINARY',\n",
    "    pre_transform=Constant() # the Reddit dataset has no node features of its own. This \"Constant\" pre-transform gives each node the value '1'.\n",
    "    # If all goes according to plan, the GCN should be able to derive good graph representations from the connectivity of the graphs alone.\n",
    ")\n",
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Contains isolated nodes: {data.contains_isolated_nodes()}')\n",
    "print(f'Contains self-loops: {data.contains_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 1000\n",
      "Number of test graphs: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/default/miniconda3/envs/deep_learning_2023/lib/python3.9/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(12345) # for reproducibility\n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "train_dataset = dataset[:1000]\n",
    "test_dataset = dataset[1000:]\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "    \n",
    "def test(model, loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(loader.dataset)  # Derive ratio of correct predictions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Welling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we've got the train loader and the test loader! Time to start doing the actual training!\n",
    "# \"A data scientist's job is 90% data, 10% science\"\n",
    "# - - - TRAINING - - -\n",
    "\n",
    "model_welling = GraphClassifierWelling(hidden_channels=64, num_node_features=1, num_classes=2)\n",
    "optimizer_welling = torch.optim.Adam(model_welling.parameters(), lr=0.1)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Train Acc: 0.5060, Test Acc: 0.4940\n",
      "Epoch: 020, Train Acc: 0.5060, Test Acc: 0.4940\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 30):\n",
    "    train(model_welling, optimizer_welling)\n",
    "    if epoch % 10 == 0:\n",
    "        train_acc = test(model_welling, train_loader)\n",
    "        test_acc = test(model_welling, test_loader)\n",
    "        print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = GraphClassifier(hidden_channels=64, num_node_features=1, num_classes=2)\n",
    "optimizer_new = torch.optim.Adam(model_new.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Train Acc: 0.6160, Test Acc: 0.6130\n",
      "Epoch: 020, Train Acc: 0.5160, Test Acc: 0.5100\n",
      "Epoch: 030, Train Acc: 0.5140, Test Acc: 0.5270\n",
      "Epoch: 040, Train Acc: 0.5980, Test Acc: 0.6130\n",
      "Epoch: 050, Train Acc: 0.7160, Test Acc: 0.7250\n",
      "Epoch: 060, Train Acc: 0.4090, Test Acc: 0.3980\n",
      "Epoch: 070, Train Acc: 0.5000, Test Acc: 0.5110\n",
      "Epoch: 080, Train Acc: 0.4940, Test Acc: 0.5060\n",
      "Epoch: 090, Train Acc: 0.3980, Test Acc: 0.3900\n",
      "Epoch: 100, Train Acc: 0.4790, Test Acc: 0.4700\n",
      "Epoch: 110, Train Acc: 0.5630, Test Acc: 0.5680\n",
      "Epoch: 120, Train Acc: 0.6160, Test Acc: 0.6220\n",
      "Epoch: 130, Train Acc: 0.5930, Test Acc: 0.5950\n",
      "Epoch: 140, Train Acc: 0.6140, Test Acc: 0.6140\n",
      "Epoch: 150, Train Acc: 0.5030, Test Acc: 0.4920\n",
      "Epoch: 160, Train Acc: 0.4740, Test Acc: 0.4740\n",
      "Epoch: 170, Train Acc: 0.6510, Test Acc: 0.6530\n",
      "Epoch: 180, Train Acc: 0.6000, Test Acc: 0.6090\n",
      "Epoch: 190, Train Acc: 0.6070, Test Acc: 0.6040\n",
      "Epoch: 200, Train Acc: 0.6270, Test Acc: 0.6270\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 201):\n",
    "    train(model_new, optimizer_new)\n",
    "    if epoch % 10 == 0:\n",
    "        train_acc = test(model_new, train_loader)\n",
    "        test_acc = test(model_new, test_loader)\n",
    "        print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you explain any differences?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
