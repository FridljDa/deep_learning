{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\":\n",
    "Deep Learning Assignment 3\n",
    "Conditional GAN Skeleton Code.\n",
    "Adopted from public sources, customized and improved for this assignment.\n",
    "\"\"\"\n",
    "\n",
    "#import necessary modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch import optim as optim\n",
    "# for visualization\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tells PyTorch to use an NVIDIA GPU, if one is available.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# loading the dataset\n",
    "training_parameters = {\n",
    "    \"img_size\": 28,\n",
    "    \"n_epochs\": 2, #24\n",
    "    \"batch_size\": 64,\n",
    "    \"learning_rate_generator\": 0.0002,\n",
    "    \"learning_rate_discriminator\": 0.0002,\n",
    "}\n",
    "# define a transform to 1) scale the images and 2) convert them into tensors\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(training_parameters['img_size']), # scales the smaller edge of the image to have this size\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# load the dataset\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST(\n",
    "        './data', # specifies the directory to download the datafiles to, relative to the location of the notebook.\n",
    "        train = True,\n",
    "        download = True,\n",
    "        transform = transform),\n",
    "    batch_size = training_parameters[\"batch_size\"],\n",
    "    shuffle=True\n",
    "    )\n",
    "\n",
    "# Fashion MNIST has 10 classes, just like MNIST. Here's what they correspond to:\n",
    "label_descriptions = {\n",
    "      0: 'T-shirt/top',\n",
    "      1\t: 'Trouser',\n",
    "      2\t: 'Pullover',\n",
    "      3\t: 'Dress',\n",
    "      4\t: 'Coat',\n",
    "      5\t: 'Sandal',\n",
    "      6\t: 'Shirt',\n",
    "      7\t: 'Sneaker',\n",
    "      8\t: 'Bag',\n",
    "      9\t: 'Ankle boot'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the Generator model class, which will be used to initialize the generator\n",
    "class Generator(nn.Module):\n",
    "  def __init__(self, input_dim, output_dim, num_labels=10): # to initialize the model-wide parameters. When you run `generator = Generator(params)`, those \"params\" are passed to __init__.\n",
    "    super(Generator,self).__init__() # initialize the parent class\n",
    "    # TODO (5.4) Turn this Generator into a Conditional Generator by\n",
    "    # 1. Adjusting the input dimension of the first hidden layer.\n",
    "    # 2. Modifying the input to the first hidden layer in the forward class.\n",
    "    # self.label_embedding = nn.Embedding(10, 10) # This function will be useful.\n",
    "    self.hidden_layer1 = nn.Sequential(\n",
    "        nn.Linear(input_dim, 256),\n",
    "        nn.LeakyReLU(0.2)\n",
    "    )\n",
    "    self.hidden_layer2 = nn.Sequential(\n",
    "        nn.Linear(256, 512),\n",
    "        nn.LeakyReLU(0.2)\n",
    "    )\n",
    "    self.hidden_layer3 = nn.Sequential(\n",
    "        nn.Linear(512, 1024),\n",
    "        nn.LeakyReLU(0.2)\n",
    "    )\n",
    "    self.hidden_layer4 = nn.Sequential(\n",
    "        nn.Linear(1024, output_dim),\n",
    "        nn.Tanh()\n",
    "    )\n",
    "  def forward(self, x, labels):\n",
    "      output = self.hidden_layer1(x)\n",
    "      output = self.hidden_layer2(output)\n",
    "      output = self.hidden_layer3(output)\n",
    "      output = self.hidden_layer4(output)\n",
    "      return output.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=1, num_labels=None):\n",
    "        super(Discriminator, self).__init__()\n",
    "        # TODO (5.4) Modify this discriminator to function as a conditional discriminator.\n",
    "        self.hidden_layer1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.hidden_layer2 = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.hidden_layer3 = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.hidden_layer4 = nn.Sequential(\n",
    "            nn.Linear(256, output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, labels=None): # labels to be used in 5.4.\n",
    "        output = self.hidden_layer1(x)\n",
    "        output = self.hidden_layer2(output)\n",
    "        output = self.hidden_layer3(output)\n",
    "        output = self.hidden_layer4(output)\n",
    "        return output.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator(784,1).to(device) # initialize both models, and load them to the GPU or CPU.\n",
    "generator = Generator(100,784).to(device)\n",
    "\n",
    "discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=training_parameters['learning_rate_discriminator'])\n",
    "generator_optimizer = optim.Adam(generator.parameters(), lr=training_parameters['learning_rate_generator'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement the GAN training procedure.\n",
    "#Loss_D - discriminator loss calculated as the sum of losses for the all real and all fake batches $(\\log (D(x))+\\log (1- D(G(z))))\n",
    "\n",
    "loss_func = nn.BCELoss() # Binary Cross Entropy Loss\n",
    "def train_generator(batch_size):\n",
    "    \"\"\"\n",
    "    Performs a training step on the generator by\n",
    "        1. Generating fake images from random noise.\n",
    "        2. Running the discriminator on the fake images.\n",
    "        3. Computing loss on the result.\n",
    "    :arg batch_size: the number of training examples in the current batch\n",
    "    Returns the average generator loss over the batch.\n",
    "    \"\"\"\n",
    "    # TODO: This function should perform a single training step on the generator\n",
    "    # Start by zeroing the gradients of the optimizer\n",
    "    generator_optimizer.zero_grad() #TODO \n",
    "    # 1. Create a new batch of fake images (since the discriminator has just been trained on the old ones)\n",
    "    noise = torch.randn(batch_size,100).to(device) # whenever you create new variables for the model to process, send them to the device, like this.\n",
    "    # ...\n",
    "    generator_output = generator(noise, labels = None) \n",
    "    # 2. Run the discriminator on the fake images\n",
    "    discriminator_output = discriminator(generator_output)\n",
    "    # 3. Compute the loss\n",
    "    loss = loss_func(discriminator_output, torch.ones(batch_size,1).to(device)) #TODO\n",
    "    loss.backward()\n",
    "    generator_optimizer.step()\n",
    "\n",
    "    loss = loss.mean().item()\n",
    "    return loss\n",
    "\n",
    "def train_discriminator(batch_size, images, labels=None): # labels to be used in 5.4.\n",
    "    \"\"\"\n",
    "    Performs a training step on the discriminator by\n",
    "        1. Generating fake images from random noise.\n",
    "        2. Running the discriminator on the fake images.\n",
    "        3. Running the discriminator on the real images\n",
    "        3. Computing loss on the results.\n",
    "    :arg batch_size: the number of training examples in the current batch\n",
    "    :arg images: the current batch of images, a tensor of size BATCH x 1 x 64 x 64\n",
    "    :arg labels: the labels corresponding to images, a tensor of size BATCH\n",
    "    Returns the average loss over the batch.\n",
    "    \"\"\"\n",
    "    # TODO: And this function should perform a single training step on the discriminator\n",
    "    discriminator_optimizer.zero_grad()\n",
    "    ###----fake images----###\n",
    "    # 1. Create a new batch of fake images (since the discriminator has just been trained on the old ones)\n",
    "    noise = torch.randn(batch_size,100).to(device) # whenever you create new variables for the model to process, send them to the device, like this.\n",
    "    # ...\n",
    "    generator_output = generator(noise, labels = None) \n",
    "    # 2. Run the discriminator on the fake images\n",
    "    discriminator_output = discriminator(generator_output)\n",
    "    # 3. Compute the loss\n",
    "    loss_fake = loss_func(discriminator_output, torch.ones(batch_size,1).to(device)) \n",
    "\n",
    "    ###----real images----###\n",
    "    # 1. Run the discriminator on the real images \n",
    "    images = torch.flatten(images, start_dim=1)\n",
    "    discriminator_output = discriminator(images)\n",
    "    # 2. Compute the loss\n",
    "    loss_real = loss_func(discriminator_output, torch.zeros(batch_size,1).to(device))   \n",
    "    \n",
    "    #combine losses\n",
    "    loss = loss_real + loss_fake\n",
    "    loss.backward()\n",
    "    discriminator_optimizer.step()\n",
    "\n",
    "    loss = loss.mean().item()\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(training_parameters['n_epochs']):\n",
    "    G_loss = []  # for plotting the losses over time\n",
    "    D_loss = []\n",
    "    for batch, (imgs, labels) in enumerate(train_loader):\n",
    "        batch_size = labels.shape[0]  # if the batch size doesn't evenly divide the dataset length, this may change on the last epoch.\n",
    "        lossG = train_generator(batch_size)\n",
    "        G_loss.append(lossG)\n",
    "        lossD = train_discriminator(batch_size, imgs, labels)\n",
    "        D_loss.append(lossD)\n",
    "\n",
    "        if ((batch + 1) % 500 == 0 and (epoch + 1) % 1 == 0):\n",
    "            # Display a batch of generated images and print the loss\n",
    "            print(\"Training Steps Completed: \", batch)\n",
    "            with torch.no_grad():  # disables gradient computation to speed things up\n",
    "                noise = torch.randn(batch_size, 100).to(device)\n",
    "                fake_labels = torch.randint(0, 10, (batch_size,)).to(device)\n",
    "                generated_data = generator(noise, fake_labels).cpu().view(batch_size, 28, 28)\n",
    "\n",
    "                # display generated images\n",
    "                batch_sqrt = int(training_parameters['batch_size'] ** 0.5)\n",
    "                fig, ax = plt.subplots(batch_sqrt, batch_sqrt, figsize=(15, 15))\n",
    "                for i, x in enumerate(generated_data):\n",
    "                    #ax[math.floor(i / batch_sqrt)][i % batch_sqrt].set_title(\n",
    "                    #    label_descriptions[int(fake_labels[i].item())]) # TODO: In 5.4 you can uncomment this line to add labels to images.\n",
    "                    ax[math.floor(i / batch_sqrt)][i % batch_sqrt].imshow(x.detach().numpy(), interpolation='nearest', cmap='gray')\n",
    "                    ax[math.floor(i / batch_sqrt)][i % batch_sqrt].get_xaxis().set_visible(False)\n",
    "                    ax[math.floor(i / batch_sqrt)][i % batch_sqrt].get_yaxis().set_visible(False)\n",
    "                # plt.show()\n",
    "                #fig.savefig(f\"./results/CGAN_Generations_Epoch_{epoch}\")\n",
    "                fig.savefig(f\"pset/pset3/results/CGAN_Generations_Epoch_{epoch}\")\n",
    "                print(\n",
    "                    f\"Epoch {epoch}: loss_d: {torch.mean(torch.FloatTensor(D_loss))}, loss_g: {torch.mean(torch.FloatTensor(G_loss))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
