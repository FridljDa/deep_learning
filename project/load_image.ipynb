{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Icon\\r', 'BENIASSA_OD.tif']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir('example_data')) #example_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/default/miniconda3/envs/deep_learning_2023/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6431, 0.6353, 0.6314, 0.6235, 0.6431, 0.6549, 0.6980, 0.7490, 0.7647,\n",
       "         0.7804],\n",
       "        [0.6745, 0.6588, 0.6392, 0.6353, 0.6667, 0.6980, 0.7490, 0.7961, 0.8078,\n",
       "         0.8196],\n",
       "        [0.7490, 0.7176, 0.6824, 0.6784, 0.7098, 0.7373, 0.7765, 0.8157, 0.8353,\n",
       "         0.8431],\n",
       "        [0.7922, 0.7451, 0.7176, 0.7451, 0.7765, 0.7882, 0.8078, 0.8353, 0.8510,\n",
       "         0.8549],\n",
       "        [0.7882, 0.7725, 0.7686, 0.7804, 0.8039, 0.8118, 0.8353, 0.8588, 0.8667,\n",
       "         0.8745],\n",
       "        [0.8039, 0.7922, 0.7922, 0.8078, 0.8196, 0.8275, 0.8471, 0.8667, 0.8745,\n",
       "         0.8824],\n",
       "        [0.8078, 0.8039, 0.8000, 0.8157, 0.8275, 0.8471, 0.8588, 0.8706, 0.8824,\n",
       "         0.8902],\n",
       "        [0.8000, 0.8000, 0.8000, 0.8078, 0.8314, 0.8510, 0.8588, 0.8667, 0.8824,\n",
       "         0.8902],\n",
       "        [0.8039, 0.8078, 0.8118, 0.8078, 0.8314, 0.8510, 0.8588, 0.8627, 0.8784,\n",
       "         0.8863],\n",
       "        [0.8157, 0.8235, 0.8275, 0.8157, 0.8314, 0.8510, 0.8588, 0.8627, 0.8745,\n",
       "         0.8863]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = Image.open('example_data/BENIASSA_OD.tif')\n",
    "image_tensor = ToTensor()(image)\n",
    "image_tensor[1,1500:1510,1500:1510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2902, 2976])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
